{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "from os import environ, chdir; chdir('../')\n",
    "conn = psycopg2.connect(dbname='postgres', \n",
    "                        user='postgres', \n",
    "                        host=environ['REDHAT_POSTGRES_1_PORT_5432_TCP_ADDR'])\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib.helpers.database_helper import pull_actions, one_hot_and_outcome\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_ids = pull_actions(action_type='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 7326), (10,), array([1, 0, 0, 1, 1, 1, 1, 0, 1, 0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_features = []\n",
    "batch_outcomes = []\n",
    "n=100\n",
    "for action in action_ids[n:n+10]:\n",
    "    this_one_hot_vec, \\\n",
    "        this_outcome = one_hot_and_outcome(action)\n",
    "    batch_features.append(np.append(this_one_hot_vec, np.ones(1)))\n",
    "    batch_outcomes.append(this_outcome)\n",
    "batch_features = np.array(batch_features)\n",
    "batch_outcomes = np.array(batch_outcomes)\n",
    "batch_features.shape, batch_outcomes.shape, batch_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.random.rand(2,7326)  # random weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = W.dot(batch_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 37.73721381,  53.59685328],\n",
       "        [ 27.75938086,  32.14392221],\n",
       "        [ 27.95305603,  31.97511924],\n",
       "        [ 37.41869667,  53.90123136],\n",
       "        [ 37.41869667,  53.90123136],\n",
       "        [ 37.41869667,  53.90123136],\n",
       "        [ 37.41869667,  53.90123136],\n",
       "        [ 27.75938086,  32.14392221],\n",
       "        [ 37.41869667,  53.90123136],\n",
       "        [ 27.75938086,  32.14392221]]), array([1, 0, 0, 1, 1, 1, 1, 0, 1, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.T, batch_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(scores, y_batch, delta=1.0, gamma=0.1):\n",
    "    correct_score = scores.T[np.arange(len(scores.T)), y_batch]\n",
    "    margins = np.maximum(0, scores - correct_score + delta).T\n",
    "    margins[np.arange(len(margins)), y_batch] = 0\n",
    "    return np.sum(margins, axis=1) + gamma*norm(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.00061402,  12.38515538,  12.02267723,   7.00061402,\n",
       "         7.00061402,   7.00061402,   7.00061402,  12.38515538,\n",
       "         7.00061402,  12.38515538])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(scores,batch_outcomes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7907b5b5cb74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7326\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.0001\u001b[0m \u001b[0;31m# generate random parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outcomes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the loss over the entire training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbestloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# keep track of the best solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbestloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbestW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "bestloss = float(\"inf\") # Python assigns the highest possible float value\n",
    "for num in range(1000):\n",
    "    W = np.random.randn(10, 7326) * 0.0001 # generate random parameters\n",
    "    loss = loss_function(scores, batch_outcomes) # get the loss over the entire training set\n",
    "    if loss < bestloss: # keep track of the best solution\n",
    "        bestloss = loss\n",
    "        bestW = W\n",
    "    print('in attempt {} the loss was {}, best {}'.format(num, loss, bestloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
